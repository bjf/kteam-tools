#!/usr/bin/env python3
#
# SWM - SRU Workflow Manager  (aka: shankbot)
#
# swm-publishing -- monitor publishing of things.
#

import os
import sys
from copy import copy
from datetime import datetime, timedelta, timezone
from math import ceil
from subprocess import Popen
#from logging import DEBUG, INFO, WARNING, basicConfig
from urllib.error import HTTPError
from urllib.parse import urlsplit, urlunsplit
from urllib.request import (HTTPBasicAuthHandler,
                            HTTPPasswordMgrWithDefaultRealm,
                            build_opener,
                            urlopen)

import yaml
from lazr.restfulclient.errors import Unauthorized

# Add ../libs to the Python search path
sys.path.append(os.path.realpath(os.path.join(os.path.dirname(__file__), os.pardir, 'libs')))

from ktl.announce import Announce
from ktl.kernel_series import KernelSeries
from ktl.swm_status import SwmStatus
from wfl.launchpad import Launchpad
#from wfl.log import Clog, cdebug, center, cleave
from wfl.snap import SnapStore, SnapStoreError


class MonitorIncompatible(Exception):
    pass


class MonitorStore:
    '''
    A backing store provider for monitor data.  This class behaves very like a
    persistent dictionary.  On instantiation it will load up the specified
    yaml file.  When the sync is called all current data is flushed back
    to the backing store.  Handles timezones being lost in the default
    yaml date format.
    '''
    def __init__(self, store_path=None):
        if store_path is None:
            store_path = 'swm-publisher.yaml'

        self.store_path = store_path
        self._store = {}
        if os.path.exists(store_path):
            with open(store_path) as rfd:
                self._store = yaml.safe_load(rfd)
                self.fix_timezones(self._store)

    # YAML saves timestamps always converted to UTC and the loses
    # this information on load dispite storing +00:00 as the data.
    # As we know they are all converted to UTC we can simply wack
    # over them with a UTC timezone.
    def fix_timezones(self, record):
        for item, item_data in record.items():
            if isinstance(item_data, datetime):
                record[item] = item_data.replace(tzinfo=timezone.utc)
            elif isinstance(item_data, dict):
                self.fix_timezones(item_data)

    # Allow a consumer to attach themselves into a specific sub-element of the
    # primary persistent store.
    def attach(self, name, owner):
        # Link an appropriate store dictionary to the owner.
        owner._store = self._store.setdefault(
            owner.__class__.__name__ + ':' + name, {})

        # Set the default value for this attribute.  Note: we pass the
        # attribute name to also (re)implement __set_name__ for older versions
        # of python3.
        for k in dir(type(owner)):
            v = getattr(type(owner), k)
            func = getattr(v, 'msa_set_default', None)
            if func is not None:
                func(owner, k)

    def __getitem__(self, key):
        return self._store[key]

    def __setitem__(self, key, value):
        self._store[key] = value

    def setdefault(self, key, value=None):
        return self._store.setdefault(key, value)

    def sync(self):
        with open(self.store_path + '.new', 'w') as wfd:
            yaml.dump(self._store, wfd, default_flow_style=False)
        os.rename(self.store_path + '.new', self.store_path)


class MonitorStoreAttr:
    '''
    This class is a Python descriptor class.  This means that an instance
    of this class may be used to replace a class attribute; all access to that
    attribute is mediated by this class.  The attribute key in the store
    is passed to the constructor, and this key is used against the owning
    objects _store attribute.  Typically this would be initialised to a
    unique key in the MonitorStore object.  Doing this renders the contents
    of this attribute persistent.

    For example:

        class MonitorThing:

            def __init__(self, backing_store):
                # Attach myself to the backing_store.  This will set appropriate
                # linkage to the myself.
                backing_store.attach('unique-key', self)
                # Default our last-date to UTC now if not present.

            # Connect the instance attribute to the backing store, supplying
            # an optional default.
            last_date = MonitorStoreAttr(default=datetime.now(timezone.utc))

            def operation(self, when):
                # Read and update attribute as normal.
                if self.last_date < when:
                    self.last_date = when
    '''
    def __init__(self, attr=None, default=None):
        self.attr = attr
        self.default = default

    def msa_set_default(self, owner, attr):
        if self.attr is None:
            attr = attr.replace('_', '-')
            self.attr = attr
        if self.attr not in owner._store:
            owner._store[self.attr] = copy(self.default)

    def __set_name__(self, owner, attr):
        if self.attr is None:
            attr = attr.replace('_', '-')
            self.attr = attr

    def __get__(self, obj, objtype=None):
        #print("__get__", self.attr, obj, objtype)
        if obj is None:
            return self
        return obj._store[self.attr]

    def __set__(self, obj, value):
        #print("__set__", self.attr, obj, value)
        obj._store[self.attr] = value


class MonitorLaunchpadArchive:

    def __init__(self, archive, lp=None, ks=None, bs=None):
        if lp is None:
            lp = Launchpad(False).default_service.launchpad
        if ks is None:
            ks = KernelSeries()
        if bs is None:
            raise ValueError("backing store not specified")

        self.lp = lp
        self.ks = ks
        self.reference = archive
        self.archive = lp.archives.getByReference(reference=archive)

        bs.attach(self.reference, self)

        # Make a quick lookup for all valid source packages.
        self.source_packages = {}
        for series in self.ks.series:
            for source in series.sources:
                for package in source.packages:
                    self.source_packages["{}:{}".format(series.codename, package.name)] = source.name

        # Validate that this archive is sufficiently public.
        try:
            self.archive.getPublishedBinaries(order_by_date=True,
                status='Published', created_since_date=self.bin_date)
        except Unauthorized:
            raise MonitorIncompatible()

    scan_base = MonitorStoreAttr(default=datetime.now(timezone.utc))
    src_date = MonitorStoreAttr(default=datetime.now(timezone.utc))
    src_replay = MonitorStoreAttr(default={})
    bin_date = MonitorStoreAttr(default=datetime.now(timezone.utc))
    bin_replay = MonitorStoreAttr(default={})

    def changed(self):
        sources = set()
        things_seen = set()

        #print(self.archive, self.src_date, self.bin_date)

        scan_base = self.scan_base - timedelta(hours=1)
        self.scan_base = datetime.utcnow()

        # Transactions can be assigned a time stamp but not committed and thus
        # not visible within the window we are scanning.  They can then commit
        # after our scan has past them and we have recorded our new start
        # point; leading us to miss them completely.  Always scan from the
        # older of the src_date and an hour window back from the last scan so
        # that we will detect such late commits.  We will detect the ones we
        # have already handled via the replay cache.
        oldest = self.src_date
        if oldest < scan_base:
            oldest = scan_base

        # Purge replay records for source publications.
        for replay_id, replay_date in list(self.src_replay.items()):
            if replay_date < oldest:
                del self.src_replay[replay_id]

        # Accumulate new source package publications.
        changed = self.archive.getPublishedSources(order_by_date=True,
            status='Published', created_since_date=oldest)
        if len(changed) > 0:
            self.src_date = changed[0].date_created
            for pub in changed:
                # Ignore this if this record is a replay.
                replay = pub.self_link.split('/')[-1]
                if replay in self.src_replay:
                    print("S", pub, "replay")
                    continue
                self.src_replay[replay] = pub.date_created

                print("S", pub, pub.date_published, pub.distro_series_link,
                    pub.source_package_name, pub.source_package_version)

                series_name = pub.distro_series_link.split('/')[-1]
                series_source_key = "{}:{}".format(series_name, pub.source_package_name)
                if series_source_key not in self.source_packages:
                    continue
                sources.add("{}:{}".format(series_name,
                    self.source_packages[series_source_key]))

        # Again transactions can retrospectivly appear in the historical
        # record, scan the older of the src_date and an hour window back from
        # the last scan.
        oldest = self.bin_date
        if oldest < scan_base:
            oldest = scan_base

        # Purge replay records for source publications.
        for replay_id, replay_date in list(self.bin_replay.items()):
            if replay_date < oldest:
                del self.bin_replay[replay_id]

        # Accumulate new binary package publications.
        changed = self.archive.getPublishedBinaries(order_by_date=True,
            status='Published', created_since_date=oldest)
        if len(changed) > 0:
            self.bin_date = changed[0].date_created
            for pub in changed:
                # Ignore this if this record is a replay.
                replay = pub.self_link.split('/')[-1]
                if replay in self.bin_replay:
                    print("B", pub, "replay")
                    continue
                self.bin_replay[replay] = pub.date_created

                #print("B?", pub, pub.date_published, pub.binary_package_name,
                #    pub.binary_package_version, pub.distro_arch_series_link)
                # All binary packages in a build is associated with the same source.
                if pub.build_link in things_seen:
                    continue
                things_seen.add(pub.build_link)
                print("B", pub, pub.date_published,
                    pub.distro_arch_series_link, pub.build.source_package_name,
                    pub.binary_package_version)
                series_name = pub.distro_arch_series_link.split('/')[-2]
                series_source_key = "{}:{}".format(series_name, pub.build.source_package_name)
                if series_source_key not in self.source_packages:
                    continue
                sources.add("{}:{}".format(series_name,
                    self.source_packages[series_source_key]))

        #print("SOURCES", sources)
        #print("APW", self._backing_store)
        return sources

    def __str__(self):
        return "Launchpad Archive Monitor {}".format(self.reference)


class MonitorLaunchpadArchivePrivate:

    def __init__(self, archive, lp=None, ks=None, bs=None):
        if lp is None:
            lp = Launchpad(False).default_service.launchpad
        if ks is None:
            ks = KernelSeries()
        if bs is None:
            raise ValueError("backing store not specified")

        self.lp = lp
        self.ks = ks
        self.reference = archive
        self.archive = lp.archives.getByReference(reference=archive)

        bs.attach(self.reference, self)

        # Get the callers private subscription URL so we can look at the
        # InRelease files later.
        #print(archive)
        me = self.lp.load(self.lp.me.self_link)
        #print("APW", me, archive)
        ##self.subscription = me.getArchiveSubscriptionURL(archive=self.archive)
        ##print("APW", self.subscription)

        # XXX: until python3 lazr.restfulclient is upgraded ....
        found = None
        find = archive[4:].split('/')
        find = '/{}/{}/{}'.format(find[0], find[2], find[1])
        for sub in me.getArchiveSubscriptionURLs():
            if sub.endswith(find):
                found = sub
                break
        #print(find, found)
        #sys.exit(1)
        if found is None:
            raise MonitorIncompatible()
        self.subscription = found

        # The current InRelease data for the archive pocket.  This will change
        # iff we have a publication change in the archive.  There is no point
        # in doing an expensive by package scan if it has not changed.  We assume
        # this is a PPA and only look at the release pocket.
        ##self.series_inrelease = {}

        # Make a quick lookup for source packages which may route here.
        self.poll_sources = []
        for series in self.ks.series:
            for source in series.sources:
                if source.supported or source.development:
                    if not source.routing:
                        continue
                    for pocket in ('build', 'proposed', 'signing', 'updates', 'security',
                            'release'):
                        dest = source.routing.lookup_destination(pocket)
                        if not dest:
                            continue
                        for route in dest:
                            if route[0] == self.reference:
                                lp_series = lp.distributions['ubuntu'].getSeries(name_or_version=series.codename)
                                self.poll_sources.append((lp_series, source))
                                self.series_inrelease.setdefault(series.codename, None)
                                #print("PP", lp_series, source)
        #print("POLL", len(self.poll_sources))

    series_inrelease = MonitorStoreAttr(default={})
    src_date = MonitorStoreAttr(default={})
    bin_date = MonitorStoreAttr(default={})

    def changed(self):
        sources = set()
        things_seen = set()

        #print(self.archive)

        series_changed = set()
        for series, series_data in self.series_inrelease.items():
            url = os.path.join(self.subscription, 'dists', series, 'InRelease')
            url_split = urlsplit(url)

            # Form the URL without username:password information.  We cannot
            # actually connect to things with this embedded as it gets miss
            # recognised as a bad port.
            clean_split = [url_split.scheme, url_split.hostname,
                url_split.path, url_split.query, url_split.fragment]
            clean_url = urlunsplit(clean_split)

            # Attach the authentication infomation to the whole domain.
            domain_split = [url_split.scheme, url_split.hostname, '/', None, None]
            domain_url =  urlunsplit(domain_split)
            #print("APW", len(domain_split), domain_url)

            # create a password manager
            password_mgr = HTTPPasswordMgrWithDefaultRealm()

            # Add the username and password.
            # If we knew the realm, we could use it instead of None.
            password_mgr.add_password(None, domain_url, url_split.username, url_split.password)

            # Instantiate the authentication handler.
            handler = HTTPBasicAuthHandler(password_mgr)

            # create "opener" (OpenerDirector instance)
            opener = build_opener(handler)

            # Grab the InRelease file using a URL without password.
            status_code = None
            try:
                inrelease = opener.open(clean_url)
                status_code = inrelease.status
            except HTTPError as e:
                status_code = e.code

            print("APW status_code={}".format(status_code))

            # If we are unable to obtain the series InRelease file assume it is changed.
            if status_code != 200:
                series_changed.add(series)
                continue

            last_modified = inrelease.getheader('Last-Modified')
            if last_modified != series_data:
                print("I?", series, series_data, '->', last_modified)
                self.series_inrelease[series] = last_modified
                series_changed.add(series)

        for series_lp, source in self.poll_sources:
            if source.series.codename not in series_changed:
                continue
            for package in source.packages:
                key = "{}:{}".format(source.series.codename, package.name)
                src_start_date = self.src_date.setdefault(key, datetime.now(timezone.utc)) # - timedelta(days=10))
                bin_start_date = self.bin_date.setdefault(key, datetime.now(timezone.utc)) # - timedelta(days=10))

                # Accumulate new source package publications.
                present = self.archive.getPublishedSources(order_by_date=True,
                    distro_series=series_lp, status='Published',
                    exact_match=True, source_name=package.name)
                for pub in present:
                    print("S?", pub, pub.date_published, pub.distro_series_link,
                        pub.source_package_name, pub.source_package_version)
                    if pub.date_published > src_start_date:
                        if pub.date_published > self.src_date[key]:
                            self.src_date[key] = pub.date_published

                        print("S", pub, pub.date_published, pub.distro_series_link,
                            pub.source_package_name, pub.source_package_version)
                        sources.add("{}:{}".format(source.series.codename, source.name))

                    # Accumulate new binary package publications.
                    changed = pub.getPublishedBinaries()
                    print("B?", len(changed))
                    for pub in changed:
                        if pub.date_published is None:
                            print("B", "no-date-published")
                            continue
                        if pub.date_published <= bin_start_date:
                            print("B", "too-old")
                            continue
                        if pub.date_published > self.bin_date[key]:
                            self.bin_date[key] = pub.date_published
                        #print("B?", pub, pub.date_published, pub.binary_package_name,
                        #    pub.binary_package_version, pub.distro_arch_series_link)
                        # All binary packages in a build is associated with the same source.
                        if pub.build_link in things_seen:
                            continue
                        things_seen.add(pub.build_link)
                        print("B", pub, pub.date_published,
                            pub.distro_arch_series_link, pub.build.source_package_name,
                            pub.binary_package_version)
                        sources.add("{}:{}".format(source.series.codename, source.name))

        #print("SOURCES", sources)
        return sources

    def __str__(self):
        return "Launchpad Private Archive Monitor {} ({})".format(self.reference, len(self.poll_sources))


class MonitorLaunchpadProject:

    def __init__(self, project, lp=None, bs=None):
        if lp is None:
            lp = Launchpad(False).default_service.launchpad
        if bs is None:
            raise ValueError("backing store not specified")

        self.lp = lp
        self.project_name = project
        self.project = lp.projects[project]

        bs.attach(self.project_name, self)

    last_date = MonitorStoreAttr(default=datetime.now(timezone.utc))

    def changed(self):
        bugs = {}
        start_date = self.last_date

        tasks = self.project.searchTasks(
            status=['In Progress', 'Incomplete', 'Fix Committed', 'Fix Released', 'Invalid'],
            omit_duplicates=False,
            modified_since=self.last_date)
        for task in tasks:
            bug = task.bug
            if bug.date_last_updated > self.last_date:
                self.last_date = bug.date_last_updated
            if 'kernel-release-tracking-bug-test' in bug.tags:
                continue
            print("TASK", task, bug, bug.date_last_updated)
            bugs[bug.id] = bug

        # Now that we have the latest update, check through the activity
        # log for each bug and consider whether it has been changed by
        # swm, if so then we can ignore it.
        changed = set()
        for bug_id, bug in bugs.items():
            dup = bug.duplicate_of
            if dup is not None:
                dup_id = bug.duplicate_of.id
                print("D", dup_id, '<-', bug_id)
                # Add both ends as SWM may have triggered the duplication.
                changed.add(str(dup_id))
                changed.add(str(bug_id))
            for activity in bug.activity:
                activity_date = activity.datechanged

                #print("D?", activity, start_date, activity_date, self.last_date)
                # We are only interested in bug activity between the start date
                # and the latest task update time (inclusive).  Scanning
                # activity after this upper bound might lead to false positives
                # and to multiple redundant scans.  We will be informed of this
                # later activity in a future run.
                if activity_date < start_date or activity_date > self.last_date:
                    continue
                #print("P?", activity, activity.person_link)
                # Why is this not lp.me.self_link ?
                if activity.person_link.endswith("/~ubuntu-kernel-bot"):
                    continue
                print("Y", bug_id, activity, activity.person_link)
                changed.add(str(bug_id))
                break

        return changed

    def __str__(self):
        return "Launchpad Project Monitor {}".format(self.project_name)


class MonitorLaunchpadQueues:

    def __init__(self, lp=None, ks=None, bs=None):
        if lp is None:
            lp = Launchpad(False).default_service.launchpad
        if ks is None:
            ks = KernelSeries()
        if bs is None:
            raise ValueError("backing store not specified")

        #archive = 'ubuntu'

        self.distro = 'ubuntu'
        self.lp = lp
        self.ks = ks
        self.bs = bs

        # Attach us to the backing store.
        bs.attach(self.distro, self)

        #self.reference = archive
        #self.archive = lp.archives.getByReference(reference=archive)

        # Make a quick lookup for all valid source packages.
        self.source_packages = {}
        for series in self.ks.series:
            for source in series.sources:
                for package in source.packages:
                    self.source_packages["{}:{}".format(series.codename, package.name)] = source.name

    last_date = MonitorStoreAttr(default=datetime.now(timezone.utc))

    def changed(self):
        start_date = self.last_date #- timedelta(hours=1)

        changed = set()
        notices = list()

        for series in self.ks.series:
            if not series.supported or series.esm:
                continue
            series_lp = self.lp.distributions[self.distro].getSeries(name_or_version=series.name)
            for status in ('New', 'Unapproved'):
                for upload in series_lp.getPackageUploads(created_since_date=start_date, status=status):
                    package_name = upload.package_name
                    # If we have no package name this is likely a signing block.
                    if package_name is None and upload.display_arches in ('uefi', 'signing'):
                        package_name = upload.display_name.split('_')[0]
                    print("QUEUE", upload, package_name, upload.status, upload.date_created)
                    package_key = "{}:{}".format(series.codename, package_name)
                    if upload.date_created > self.last_date:
                        self.last_date = upload.date_created
                    if package_key not in self.source_packages:
                        continue
                    source_key = "{}:{}".format(series.codename, self.source_packages[package_key])
                    if source_key in changed:
                        continue
                    changed.add(source_key)
                    notices.append("{} {} on {} queue for {}".format(series.codename, package_name, status, upload.pocket))
                sys.stdout.flush()

        if len(notices) > 0:
            announce = Announce()
            for notice in notices:
                print("ANNOUNCE", notice)
                announce.send('swm-queued-item', notice)

        return changed

    def __str__(self):
        return "Launchpad Queue Monitor {}".format(self.distro)


class MonitorSnapStore:

    def __init__(self, snap, bs=None):
        if bs is None:
            raise ValueError("backing store not specified")
        if snap.publish_to is None:
            raise ValueError("snap {} is not published to any tracks".format(snap.name))
        if snap.promote_to is None:
            raise ValueError("snap {} is not promoted to any risks".format(snap.name))

        self.snap = snap
        self.snap_store = SnapStore(snap)

        bs.attach(str(self.snap), self)

    last_date = MonitorStoreAttr(default=datetime.now(timezone.utc))

    def changed(self):
        changed = set()
        start_date = self.last_date

        #print(self.snap)

        try:
            data = self.snap_store.channel_map()
        except SnapStoreError as e:
            print("Snap lookup failed: " + str(e))
            return changed

        for arch, tracks in self.snap.publish_to.items():
            for track in tracks:
                for risk in self.snap.promote_to:
                    channel = "{}/{}".format(track, risk)
                    #print("?", self.snap.name, arch, channel)
                    key = (arch, channel)
                    if key not in data:
                        continue

                    # Convert the iso8601 format timestring into one
                    # which strptime actually can parse.
                    released_at = data[key]['released-at']
                    released_at = released_at[:-3] + released_at[-2:]
                    #print("D?", released_at)

                    date_published = datetime.strptime(released_at,
                        "%Y-%m-%dT%H:%M:%S.%f%z")
                    #print(date_published, '>', self.last_date)
                    if date_published > self.last_date:
                        self.last_date = date_published

                    #print(date_published, start_date)
                    if date_published > start_date:
                        print("P", self.snap.name, arch, channel)
                        changed.add("{}:{}:{}".format(
                            self.snap.source.series.codename,
                            self.snap.source.name, self.snap.name))

        return changed

    def __str__(self):
        return "Snapstore Snap Monitor {}:{}:{}".format(
            self.snap.source.series.codename,
            self.snap.source.name, self.snap.name)


class MonitorStatusSwmStatus:

    def __init__(self, status_path, project, lp=None, bs=None):
        if lp is None:
            lp = Launchpad(False).default_service.launchpad
        if bs is None:
            raise ValueError("backing store not specified")

        self.status_path = status_path
        self.lp = lp
        self.project_name = project
        self.project = self.lp.projects[project]

        bs.attach(status_path + '--' + project, self)

    new_bugs = MonitorStoreAttr(default={})
    new_bugs_last = MonitorStoreAttr(default=datetime.now(timezone.utc) - timedelta(days=90))


    def status_key(self, item):
        (bug_id, bug_data) = item

        # Sort by lowest last scanned date.
        return (bug_data.get('manager', {}).get('time-scanned') or
            datetime.utcnow() - timedelta(days=10*365), bug_id)

    def changed(self):
        changed = set()
        start_date = datetime.utcnow() # - timedelta(minutes=60)

        status = SwmStatus(path=self.status_path)

        # Scan the live trackers and trigger any which have past their refresh
        # time.  Also accumulate any which have not been scanned for 4 hours.
        lagging = []
        for bug_id, bug_data in sorted(status.trackers.items(), key=self.status_key):
            if 'refresh' in bug_data:
                (when, why) = bug_data['refresh']
                print("REFRESH {} time={} delta={} trigger={} reason={}".format(bug_id, when, when - start_date, when < start_date, why))
                #print("APW", bug_id, bug_data['refresh-time'], start_date)
                #print("APW", bug_data['refresh-time'] - start_date, bug_data['refresh-time'] < start_date)
                if when < start_date:
                    #print("APW", bug_id, bug_data['refresh-time'], "READY")
                    changed.add(bug_id)

            scanned = bug_data.get('manager', {}).get('time-scanned')
            if scanned is not None:
                scan_refresh = scanned + timedelta(hours=3, minutes=30)
                if scan_refresh < start_date:
                    delta = scan_refresh - start_date
                    print("LAGGING {} time={} delta={} trigger={}".format(bug_id, scan_refresh, delta, scan_refresh < start_date))
                    lagging.append((scan_refresh, delta, bug_id))

        # Run the list of lagging trackers and try and spread them out over the cycle without
        # letting them lag too long.  Try not to batch up too many updates either as a timeout
        # in a batch is fatal.  Basically, spread out the entire pending pile over the 'next'
        # hour.
        limit = ceil(len(lagging) / (60/5))
        print("SCANNER trackers={} lagging={} limit={}".format(len(status.trackers), len(lagging), limit))
        for scan_refresh, delta, bug_id in sorted(lagging):
            print("LAGGER {} time={} delta={}".format(bug_id, scan_refresh, delta))
            changed.add(bug_id)

            limit -= 1
            if limit == 0:
                break

        #print("REFRESH", changed)

        # Record all newly added trackers.  If they are not in status trigger them.
        # Keep track of such newly added trackers until they are added to status
        # as these are seemingly lost.
        start_date = self.new_bugs_last
        tasks = self.project.searchTasks(
            status=['In Progress'],
            tags=['kernel-release-tracking-bug-live'],
            modified_since=self.new_bugs_last)
        for task in tasks:
            bug = task.bug
            if bug.date_last_updated > self.new_bugs_last:
                self.new_bugs_last = bug.date_last_updated
            print("TASK", task, task.status, bug, bug.date_last_updated)

            # If we have it in status we are good to ignore it.
            bug_id = str(bug.id)
            if bug_id in status.trackers:
                continue

            print("NEW-ADDED", bug_id)
            self.new_bugs[bug_id] = True
        # Drop any which have now been seen.
        for bug_id in list(self.new_bugs):
            if bug_id in status.trackers:
                print("NEW-REMOVED", bug_id)
                del self.new_bugs[bug_id]
                continue

            bug = self.lp.bugs[bug_id]
            if bug.duplicate_of is not None:
                print("NEW-DUPLICATE", bug_id)
                del self.new_bugs[bug_id]
                continue

            print("NEW", bug_id)
            changed.add(bug_id)

        return changed

    def __str__(self):
        return "Status refresh_time Monitor"


class MonitorAutomatedTesting:

    def __init__(self, adt_url, bs=None):
        if bs is None:
            raise ValueError("backing store not specified")
        self.adt_url = adt_url

        bs.attach(self.adt_url, self)

    test_status = MonitorStoreAttr(default={})

    def changed(self):
        changed = set()

        with urlopen(self.adt_url) as status:
            ##print(status, status.status)
            for line in status.read().decode('utf-8').split('\n'):
                bits = line.split(None, 4)
                if len(bits) < 4:
                    continue
                (series, source, version, state) = bits[0:4]
                key = "{}:{}".format(series, source)
                if self.test_status.setdefault(key, state) != state:
                    changed.add(key)
                    self.test_status[key] = state

        #print("TESTING", changed)

        return changed

    def __str__(self):
        return "Automated Testing Monitor"


class MonitorFactory:

    def __init__(self, lp=None, ks=None, bs=None):
        self._lp = lp
        self._ks = ks
        self._bs = bs

    @property
    def lp(self):
        if self._lp is None:
            self._lp = Launchpad(False).default_service.launchpad
        return self._lp

    @property
    def ks(self):
        if self._ks is None:
            self._ks = KernelSeries()
        return self._ks

    @property
    def bs(self):
        if self._bs is None:
            self._bs = MonitorStore('swm-publishing.yaml')
        return self._bs

    def kernel_series_archives(self):
        # Find out which archives we may be publishing to and which
        # series/package combinations are interesting to us.
        archive_names = set()
        for series in self.ks.series:
            for source in series.sources:
                if source.supported or source.development:
                    if not source.routing:
                        continue
                    for pocket in ('build', 'proposed', 'signing', 'updates', 'security',
                            'release'):
                        dest = source.routing.lookup_destination(pocket)
                        if not dest:
                            continue
                        for route in dest:
                            archive_names.add(route[0])

        monitors = []
        for archive_name in archive_names:
            monitor = None
            try:
                monitor = MonitorLaunchpadArchive(archive_name, lp=self.lp, ks=self.ks, bs=self.bs)
            except MonitorIncompatible:
                pass
            if monitor is None:
                try:
                    monitor = MonitorLaunchpadArchivePrivate(archive_name, lp=self.lp, ks=self.ks, bs=self.bs)
                except MonitorIncompatible:
                    pass
            if monitor is not None:
                monitors.append(monitor)
            else:
                print("WARNING: {}: archive cannot be scanned", archive_name)

        return monitors

    def launchpad_project(self, project):
        return [MonitorLaunchpadProject(project, lp=self.lp, bs=self.bs)]

    def launchpad_queues(self):
        return [MonitorLaunchpadQueues(lp=self.lp, ks=self.ks, bs=self.bs)]

    def kernel_series_snaps(self):
        snaps = []
        for series in self.ks.series:
            for source in series.sources:
                if source.supported or source.development:
                    for snap in source.snaps:
                        if (snap.promote_to is not None and
                                snap.publish_to is not None):
                            snaps.append(MonitorSnapStore(snap, bs=self.bs))
        return snaps

    def swm_status(self, status_path, project):
        return [MonitorStatusSwmStatus(status_path, project, lp=self.lp, bs=self.bs)]

    def automated_testing(self, adt_url):
        return [MonitorAutomatedTesting(adt_url, bs=self.bs)]

    def sync(self):
        self.bs.sync()

    def __str__(self):
        return "Private Archive Monitor {}".format(self.reference)


if __name__ == '__main__':
    factory = MonitorFactory()

    monitors = []
    monitors += factory.kernel_series_archives()
    monitors += factory.launchpad_project('kernel-sru-workflow')
    monitors += factory.kernel_series_snaps()
    monitors += factory.swm_status('status.yaml', 'kernel-sru-workflow')
    monitors += factory.automated_testing('https://people.canonical.com/~kernel/status/adt-matrix/overall.txt')
    monitors += factory.launchpad_queues()

    command = None

    # Look for updates in each monitor.
    changed = set()
    for monitor in monitors:
        print("***", monitor)
        sys.stdout.flush()
        new = monitor.changed()
        if len(new) > 0:
            print(monitor, "CHANGED", list(new))
        sys.stdout.flush()
        changed = changed | new
    print("CHANGED", changed)

    sys.stdout.flush()

    if len(changed) > 0:
        cmd = ['./swm-cron', '--dependants'] + list(changed)
        command = Popen(cmd)
        print("COMMAND STARTED", command.pid)
        sys.stdout.flush()
        status = command.wait()
        print("COMMAND COMPLETE", status)
        if status != 0:
            sys.exit(1)

    # All is done, update the backing store.
    factory.sync()
